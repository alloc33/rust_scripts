// TCP SERVER + WORKER POOL (Combining Your Knowledge)
// This is THE pattern for production servers
// Time to code: 15 minutes

use std::io::Read;
use std::io::Write;
use std::net::TcpListener;
use std::net::TcpStream;
use std::sync::Arc;
use std::sync::Mutex;
use std::sync::mpsc;
use std::thread;

// Simple thread pool from previous example
// This is the foundation for handling multiple TCP connections efficiently
struct ThreadPool {
    workers: Vec<thread::JoinHandle<()>>, // Worker thread handles
    sender: mpsc::Sender<Box<dyn FnOnce() + Send + 'static>>, // Job queue
}

impl ThreadPool {
    fn new(size: usize) -> Self {
        // Create channel for job distribution
        let (sender, receiver) = mpsc::channel::<Box<dyn FnOnce() + Send + 'static>>();
        // Share receiver across all workers using Arc<Mutex>
        let receiver = Arc::new(Mutex::new(receiver));

        let mut workers = Vec::with_capacity(size);

        // Spawn worker threads that will handle TCP connections
        for id in 0..size {
            let receiver = Arc::clone(&receiver);

            let handle = thread::spawn(move || {
                loop {
                    // Wait for a job (blocking)
                    let job = receiver.lock().unwrap().recv();

                    match job {
                        Ok(job) => {
                            println!("[Worker {}] Processing request", id);
                            job(); // Execute the connection handler
                        },
                        Err(_) => {
                            // Channel closed - server shutting down
                            println!("[Worker {}] Shutting down", id);
                            break;
                        },
                    }
                }
            });

            workers.push(handle);
        }

        ThreadPool { workers, sender }
    }

    // Submit a connection handler to the pool
    fn execute<F>(&self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        // Send the job through the channel
        // One of the workers will pick it up
        self.sender.send(Box::new(f)).unwrap();
    }
}

impl Drop for ThreadPool {
    fn drop(&mut self) {
        // sender is dropped automatically (closes the channel)
        // This signals all workers to exit after finishing current jobs

        // Wait for all workers to finish gracefully
        while let Some(worker) = self.workers.pop() {
            worker.join().unwrap();
        }
        // Clean shutdown - no requests dropped, no panics
    }
}

// Handle a single HTTP request
// This runs in a worker thread from the pool
fn handle_connection(mut stream: TcpStream) {
    let mut buffer = [0; 1024];

    match stream.read(&mut buffer) {
        Ok(n) => {
            // Parse HTTP request (first line only for demo)
            let request = String::from_utf8_lossy(&buffer[..n]);
            println!("[Handler] Request: {}", request.lines().next().unwrap_or(""));

            // Simple HTTP response
            // In production: parse request, route to handler, generate response
            let response = "HTTP/1.1 200 OK\r\n\
                           Content-Type: text/plain\r\n\
                           \r\n\
                           Hello from worker pool!";

            // Write response back to client
            stream.write_all(response.as_bytes()).ok();
            stream.flush().ok();
            // Stream is automatically closed when it goes out of scope
        },
        Err(e) => eprintln!("[Handler] Error reading: {}", e),
    }
}

fn main() -> std::io::Result<()> {
    println!("üöÄ TCP Server + Worker Pool\n");

    // Bind to TCP port - this is the main thread's job
    let listener = TcpListener::bind("127.0.0.1:7878")?;

    // Create worker pool with 4 threads
    // These threads will handle all incoming connections
    let pool = ThreadPool::new(4);

    println!("Server listening on http://127.0.0.1:7878");
    println!("Test with: curl http://localhost:7878\n");
    println!("Press Ctrl+C to stop\n");

    // Main event loop: accept connections
    // This is single-threaded and FAST (just accept + dispatch)
    for stream in listener.incoming() {
        match stream {
            Ok(stream) => {
                // Don't handle connection here - send to worker pool!
                // Main thread immediately goes back to accepting connections
                pool.execute(|| {
                    handle_connection(stream); // Executed by a worker
                });
            },
            Err(e) => {
                eprintln!("Connection failed: {}", e);
            },
        }
    }

    // When loop exits (Ctrl+C), pool is dropped
    // Drop implementation waits for workers to finish
    Ok(())
}

/*
WHAT'S HAPPENING HERE:

1. TcpListener accepts connections (main thread)
2. Each connection sent to worker pool via channel
3. Workers process requests in parallel
4. Main thread keeps accepting new connections

WHY THIS IS BETTER THAN YOUR PREVIOUS TCP SERVER:

BEFORE (one thread per connection):
‚ùå 1000 connections = 1000 threads = OOM
‚ùå Thread creation overhead
‚ùå No control over concurrency

NOW (worker pool):
‚úÖ Fixed number of threads (4)
‚úÖ Can handle 1000s of connections
‚úÖ Bounded resource usage
‚úÖ Backpressure (if using sync_channel)

PRODUCTION IMPROVEMENTS:

1. Use sync_channel for backpressure:
   let (sender, receiver) = mpsc::sync_channel(100);

2. Add graceful shutdown:
   let shutdown = Arc::new(AtomicBool::new(false));

3. Add timeouts:
   stream.set_read_timeout(Some(Duration::from_secs(5)))?;

4. Add error handling:
   Result<(), ServerError> everywhere

5. Add metrics:
   let requests_handled = Arc::new(AtomicUsize::new(0));

WHEN TO USE THIS VS TOKIO:

USE THIS (threads + channels):
‚úÖ < 1000 concurrent connections
‚úÖ CPU-bound work
‚úÖ Simple deployment
‚úÖ Easy to debug
‚úÖ Your case!

USE TOKIO (async):
‚úÖ 10,000+ concurrent connections
‚úÖ I/O-bound work
‚úÖ Need to await multiple things
‚úÖ Calling async APIs
‚úÖ You're Discord/Cloudflare

BENCHMARK THIS:

// Threads + channels
- 1000 req/sec: Easy
- 10,000 req/sec: Doable
- 100,000 req/sec: Use tokio

COMBINING WITH YOUR KNOWLEDGE:

You know:
‚úÖ TcpListener/TcpStream
‚úÖ Blocking I/O
‚úÖ HTTP parsing

Add:
‚úÖ Channels (today)
‚úÖ Worker pool (today)
‚úÖ Arc<Mutex<>> (when needed)

= Production-ready server!

NEXT STEPS:

1. Run this server
2. Benchmark with: ab -n 1000 -c 10 http://localhost:7878/
3. Compare to your single-threaded version
4. Add graceful shutdown (from earlier pattern)
5. Add metrics with AtomicUsize

DON'T LEARN TOKIO YET!
This pattern will serve you for 99% of use cases.

TIME: 15 minutes to code from memory
REPLACES: Most of what you'd use tokio for
*/
